{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测模块工作过程：\n",
    "\n",
    "预测模块根据输入的地图数据，以及传感器融合的数据，生成并输出一些预测数据，\n",
    "\n",
    "这些预测数据，包含了周围所有其他机动车以及其他移动物体的未来状态。\n",
    "\n",
    "通常，这些预测数据可以展示为若干可能的运动轨迹。\n",
    "\n",
    "预测数据还包括每条轨迹的几率大小；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测技术：\n",
    "\n",
    "1.基于模型法\n",
    "\n",
    "使用运动数学模型，预测运动轨迹，\n",
    "\n",
    "2.数据驱动法\n",
    "\n",
    "依赖于机器学习和案例学习\n",
    "\n",
    "![](./p002.png)\n",
    "\n",
    "\n",
    "基于模型方法吸收了有关物理限制的知识(来自道路交通状况等)，而机器学习可以根据大量历史数据来学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据驱动法\n",
    "\n",
    "一般分两个阶段：\n",
    "\n",
    "第一阶段，离线训练阶段，，算法从数据中学习模式；\n",
    "\n",
    "用轨迹聚合算法\n",
    "\n",
    "![](./p003.png)\n",
    "\n",
    "第二阶段，在线预测阶段，算法使用模型来预测；\n",
    "\n",
    "![](./p004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于模型法\n",
    "\n",
    "## Frenet Coordinates\n",
    "\n",
    "以无人车为原点，横向位移为d,纵向位移为s\n",
    "\n",
    "![](./p006.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Paper\n",
    "You can find the paper here: A comparative study of multiple-model algorithms for maneuvering target tracking\n",
    "    \n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2017/June/5953fc34_a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking/a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking.pdf\n",
    "        \n",
    "\n",
    "辅助材料\n",
    " A comparative study of multiple-model algorithms for maneuvering target tracking\n",
    " \n",
    " http://video.udacity-data.com.s3.amazonaws.com/topher/2017/June/5953fc34_a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking/a-comparative-study-of-multiple-model-algorithms-for-maneuvering-target-tracking.pdf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Defining Process Models\n",
    "You saw how process models can vary in complexity from very simple...\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\dot{s}\\\\ \\dot{d} \\end{bmatrix}=\\begin{bmatrix} s_{0} \\\\ 0 \\end{bmatrix} + {w}\n",
    "$$\n",
    "\n",
    "\n",
    "to very complex...\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\ddot{s} \\\\ \\ddot{d} \\\\ \\ddot{\\theta} \\end{bmatrix} = \\begin{bmatrix} \\dot{\\theta}\\dot{d} + a_s \\\\ -\\dot{\\theta}\\dot{s} + \\frac{2}{m}(F_{c,f}\\cos\\delta + F_{c,r}) \\\\ \\frac{2}{I_z} (l_f F_{c,f} - l_rF_{c,r}) \\end{bmatrix} + {w} \n",
    "$$\n",
    "\n",
    "![](./p100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Using process models to compare driver behavior to what would be expected for each model.\n",
    "\n",
    "![](./p102.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Classifying Intent with Multiple Model Algorithm\n",
    "\n",
    "![](./p104.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两种方法的对比\n",
    "![](./p105.png)\n",
    "\n",
    "实践中，最好的预测方法通常是某种混合方法，结合以上两种方法的长处，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在行为分类的混合法中，经常使用的一个策略是，把分类器和过滤器相结合，\n",
    "\n",
    "![](./p107.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++实现朴素贝叶斯\n",
    "\n",
    "预测轨迹类别：\n",
    "\n",
    "1.change lanes left (shown in blue)\n",
    "\n",
    "2.keep lane (shown in black)\n",
    "\n",
    "3.or change lanes right (shown in red)\n",
    "\n",
    "![](./p108.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each coordinate contains 4 features:\n",
    "\n",
    "s\n",
    "\n",
    "d\n",
    "\n",
    "$\\dot{s} $\n",
    "\n",
    "$\\dot{d} $\n",
    "\n",
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Implement the train(data, labels) method in the class GNB in classifier.cpp.\n",
    "\n",
    "Training a Gaussian Naive Bayes classifier consists of computing and storing the mean and standard deviation from the data for each label/feature pair. For example, given the label \"change lanes left” and the feature $\\dot{s}$\n",
    " , it would be necessary to compute and store the mean and standard deviation of $\\dot{s} $\n",
    "\n",
    "  over all data points with the \"change lanes left” label.\n",
    "\n",
    "Additionally, it will be convenient in this step to compute and store the prior probability p(C_k) for each label C_k. This can be done by keeping track of the number of times each label appears in the training data.\n",
    "\n",
    "### 2.Implement the predict(observation) method in classifier.cpp.\n",
    "\n",
    "![](./p200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Resources\n",
    "\n",
    "sklearn documentation on GaussianNB\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
    "\n",
    "\n",
    "Wikipedia article on Naive Bayes / GNB\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Constructing_a_classifier_from_the_probability_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码实现：\n",
    "```\n",
    "#include \"classifier.h\"\n",
    "#include <math.h>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "\n",
    "using Eigen::ArrayXd;\n",
    "using std::string;\n",
    "using std::vector;\n",
    "\n",
    "// Initializes GNB\n",
    "GNB::GNB() {\n",
    "  /**\n",
    "   * TODO: Initialize GNB, if necessary. May depend on your implementation.\n",
    "   */\n",
    "  left_means = ArrayXd(4);\n",
    "  left_means << 0,0,0,0;\n",
    "  \n",
    "  left_sds = ArrayXd(4);\n",
    "  left_sds << 0,0,0,0;\n",
    "    \n",
    "  left_prior = 0;\n",
    "    \n",
    "  keep_means = ArrayXd(4);\n",
    "  keep_means << 0,0,0,0;\n",
    "  \n",
    "  keep_sds = ArrayXd(4);\n",
    "  keep_sds << 0,0,0,0;\n",
    "  \n",
    "  keep_prior = 0;\n",
    "  \n",
    "  right_means = ArrayXd(4);\n",
    "  right_means << 0,0,0,0;\n",
    "  \n",
    "  right_sds = ArrayXd(4);\n",
    "  right_sds << 0,0,0,0;\n",
    "  \n",
    "  right_prior = 0;\n",
    "}\n",
    "\n",
    "GNB::~GNB() {}\n",
    "\n",
    "void GNB::train(const vector<vector<double>> &data, \n",
    "                const vector<string> &labels) {\n",
    "  /**\n",
    "   * Trains the classifier with N data points and labels.\n",
    "   * @param data - array of N observations\n",
    "   *   - Each observation is a tuple with 4 values: s, d, s_dot and d_dot.\n",
    "   *   - Example : [[3.5, 0.1, 5.9, -0.02],\n",
    "   *                [8.0, -0.3, 3.0, 2.2],\n",
    "   *                 ...\n",
    "   *                ]\n",
    "   * @param labels - array of N labels\n",
    "   *   - Each label is one of \"left\", \"keep\", or \"right\".\n",
    "   *\n",
    "   * TODO: Implement the training function for your classifier.\n",
    "   */\n",
    "  \n",
    "  // For each label, compute ArrayXd of means, one for each data class \n",
    "  //   (s, d, s_dot, d_dot).\n",
    "  // These will be used later to provide distributions for conditional \n",
    "  //   probabilites.\n",
    "  // Means are stored in an ArrayXd of size 4.\n",
    "  \n",
    "  float left_size = 0;\n",
    "  float keep_size = 0;\n",
    "  float right_size = 0;\n",
    "  \n",
    "  // For each label, compute the numerators of the means for each class\n",
    "  //   and the total number of data points given with that label.\n",
    "  for (int i=0; i<labels.size(); ++i) {\n",
    "    if (labels[i] == \"left\") {\n",
    "      // conversion of data[i] to ArrayXd\n",
    "      left_means += ArrayXd::Map(data[i].data(), data[i].size());\n",
    "      left_size += 1;\n",
    "    } else if (labels[i] == \"keep\") {\n",
    "      keep_means += ArrayXd::Map(data[i].data(), data[i].size());\n",
    "      keep_size += 1;\n",
    "    } else if (labels[i] == \"right\") {\n",
    "      right_means += ArrayXd::Map(data[i].data(), data[i].size());\n",
    "      right_size += 1;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Compute the means. Each result is a ArrayXd of means \n",
    "  //   (4 means, one for each class)\n",
    "  left_means = left_means/left_size;\n",
    "  keep_means = keep_means/keep_size;\n",
    "  right_means = right_means/right_size;\n",
    "  \n",
    "  // Begin computation of standard deviations for each class/label combination.\n",
    "  ArrayXd data_point;\n",
    "  \n",
    "  // Compute numerators of the standard deviations.\n",
    "  for (int i=0; i<labels.size(); ++i) {\n",
    "    data_point = ArrayXd::Map(data[i].data(), data[i].size());\n",
    "    if (labels[i] == \"left\"){\n",
    "      left_sds += (data_point - left_means)*(data_point - left_means);\n",
    "    } else if (labels[i] == \"keep\") {\n",
    "      keep_sds += (data_point - keep_means)*(data_point - keep_means);\n",
    "    } else if (labels[i] == \"right\") {\n",
    "      right_sds += (data_point - right_means)*(data_point - right_means);\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // compute standard deviations\n",
    "  left_sds = (left_sds/left_size).sqrt();\n",
    "  keep_sds = (keep_sds/keep_size).sqrt();\n",
    "  right_sds = (right_sds/right_size).sqrt();\n",
    "    \n",
    "  //Compute the probability of each label\n",
    "  left_prior = left_size/labels.size();\n",
    "  keep_prior = keep_size/labels.size();\n",
    "  right_prior = right_size/labels.size();\n",
    "}\n",
    "\n",
    "string GNB::predict(const vector<double> &sample) {\n",
    "  /**\n",
    "   * Once trained, this method is called and expected to return \n",
    "   *   a predicted behavior for the given observation.\n",
    "   * @param observation - a 4 tuple with s, d, s_dot, d_dot.\n",
    "   *   - Example: [3.5, 0.1, 8.5, -0.2]\n",
    "   * @output A label representing the best guess of the classifier. Can\n",
    "   *   be one of \"left\", \"keep\" or \"right\".\n",
    "   *\n",
    "   * TODO: Complete this function to return your classifier's prediction\n",
    "   */\n",
    "  \n",
    "  // Calculate product of conditional probabilities for each label.\n",
    "  double left_p = 1.0;\n",
    "  double keep_p = 1.0;\n",
    "  double right_p = 1.0; \n",
    "\n",
    "  for (int i=0; i<4; ++i) {\n",
    "    left_p *= (1.0/sqrt(2.0 * M_PI * pow(left_sds[i], 2))) \n",
    "            * exp(-0.5*pow(sample[i] - left_means[i], 2)/pow(left_sds[i], 2));\n",
    "    keep_p *= (1.0/sqrt(2.0 * M_PI * pow(keep_sds[i], 2)))\n",
    "            * exp(-0.5*pow(sample[i] - keep_means[i], 2)/pow(keep_sds[i], 2));\n",
    "    right_p *= (1.0/sqrt(2.0 * M_PI * pow(right_sds[i], 2))) \n",
    "            * exp(-0.5*pow(sample[i] - right_means[i], 2)/pow(right_sds[i], 2));\n",
    "  }\n",
    "\n",
    "  // Multiply each by the prior\n",
    "  left_p *= left_prior;\n",
    "  keep_p *= keep_prior;\n",
    "  right_p *= right_prior;\n",
    "    \n",
    "  double probs[3] = {left_p, keep_p, right_p};\n",
    "  double max = left_p;\n",
    "  double max_index = 0;\n",
    "\n",
    "  for (int i=1; i<3; ++i) {\n",
    "    if (probs[i] > max) {\n",
    "      max = probs[i];\n",
    "      max_index = i;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return this -> possible_labels[max_index];\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
